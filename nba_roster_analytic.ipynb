{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping using Beautiful Soup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This study is part of a serie of statistical analysis in the composition and salary earned by main and key players in the NBA.\n",
    "\n",
    "I am using Beautiful Soup for the this Python app. Beautiful Soup is a Python library for parsing data out of HTML and XML files (aka webpages). It works with your favorite parser to provide idiomatic ways of navigating, searching, and modifying the parse tree.\n",
    "\n",
    "The data I used came from Atlanta Hawks Roster. Reference: https://www.espn.com/nba/team/roster/_/name/atl/atlanta-hawks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Home Page](images/home.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology\n",
    "\n",
    "1. Import Modules\n",
    "2. Get the URL link\n",
    "3. Navigate the URL Data Structure\n",
    "4. Testing out data requests\n",
    "5. Write data to a file in pseudo-code:\n",
    "    + Open up a file to write in and append data. \n",
    "    + Write headers\n",
    "    + Run for loop that will make it clean the HTML tags and add their values in an array results\n",
    "    + Run for loop that will write elements of the array to file\n",
    "    + When complete, close the file\n",
    "6. The output file in CSV format.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main goal\n",
    "\n",
    "+ To access all of the content from the source code of the webpage with Python\n",
    "+ Parse and extract data. \n",
    "+ Save the info in CSV file for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data info extracted:\n",
    "\n",
    "Name, POS ,Age ,HT ,WT ,College and Salary of Team Roster\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Atlanta Hawks Roster](images/Atlanta-Hawks-Roster.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't have Beautiful Soup, install with 'conda install beautifulsoup' in terminal.\n",
    "\n",
    "Python requires us to explicitly load the libraries that we want to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load a webpage into python so that we can parse it and manipulate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "URL = 'https://www.espn.com/nba/team/roster/_/name/atl/atlanta-hawks'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Control of Connection. We just turned the website code into a Python object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(URL)\n",
    "soup = bs4.BeautifulSoup(response.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all the tags with class city or number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = soup.findAll(attrs={'class':['inline']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Source Code HTML](images/code.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open new file, make sure path to your data file is correct.\n",
    "\n",
    "Later, I write headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('hilca_nba_team_roster.csv','w') \n",
    "f.write(\"Name\\tPos\\tAge\\tHT\\tWT\\tCollege\\tSalary\" + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear HTML tag and assign to the array results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for element in data:\n",
    "    TAG_RE = re.compile(r'<[^>]+>')\n",
    "    text = TAG_RE.sub('', str(element))\n",
    "    results.append(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "for item in results:\n",
    "    if not item:\n",
    "        i = 0\n",
    "        j = j + 1\n",
    "        if j > 1: f.write(\"\\n\")\n",
    "    else:\n",
    "        i = i + 1\n",
    "        if (i == 1): f.write(item + \"\\t\") # write name and add tabulator\n",
    "        if (i == 2): f.write(item + \"\\t\") # write pos and add tabulator\n",
    "        if (i == 3): f.write(item + \"\\t\") # write age and add tabulator\n",
    "        if (i == 4): f.write(item + \"\\t\") # write ht and add tabulator\n",
    "        if (i == 5): f.write(item + \"\\t\") # write wt and add tabulator\n",
    "        if (i == 6): f.write(item + \"\\t\") # write college and add tabulator\n",
    "        if (i == 7): f.write(item) # write salary and add tabulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close() # close file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cvs data](images/cvs.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "We used Beautiful Soup as the main tool. The major concept with Beautiful Soup is that it allows you to access elements of your page by following the CSS structures, such as grabbing all links, all headers, specific classes, or more. It is a powerful library.\n",
    "\n",
    " Once we grab elements, Python makes it easy to write the elements or relevant components of the elements into other files, such as a CSV, that can be stored in a database or opened in other software."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
